{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aad811f-b203-4075-abcc-ac5f831d25ea",
   "metadata": {},
   "source": [
    "# GDrive link : https://drive.google.com/drive/folders/1wlbQrEngdQ4RfjVSUwWJi1s0z6zWisTp?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51a9d8e2-7a3e-4464-8004-2b1cdfbffd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model =  KNN\n",
      "Validation Accuracy: 0.9066037735849056\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.93      0.88      0.90       513\n",
      "        real       0.89      0.93      0.91       547\n",
      "\n",
      "    accuracy                           0.91      1060\n",
      "   macro avg       0.91      0.91      0.91      1060\n",
      "weighted avg       0.91      0.91      0.91      1060\n",
      "\n",
      "Confusion Matrix:\n",
      "[[462  51]\n",
      " [ 32 515]]\n",
      "Test Accuracy: 0.9216981132075471\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.94      0.90      0.92       513\n",
      "        real       0.91      0.94      0.93       547\n",
      "\n",
      "    accuracy                           0.92      1060\n",
      "   macro avg       0.92      0.92      0.92      1060\n",
      "weighted avg       0.92      0.92      0.92      1060\n",
      "\n",
      "Model =  Logistic\n",
      "Validation Accuracy: 0.9292452830188679\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.92      0.93      0.93       513\n",
      "        real       0.93      0.93      0.93       547\n",
      "\n",
      "    accuracy                           0.93      1060\n",
      "   macro avg       0.93      0.93      0.93      1060\n",
      "weighted avg       0.93      0.93      0.93      1060\n",
      "\n",
      "Confusion Matrix:\n",
      "[[473  40]\n",
      " [ 42 505]]\n",
      "Test Accuracy: 0.9226415094339623\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.92      0.92      0.92       513\n",
      "        real       0.93      0.92      0.92       547\n",
      "\n",
      "    accuracy                           0.92      1060\n",
      "   macro avg       0.92      0.92      0.92      1060\n",
      "weighted avg       0.92      0.92      0.92      1060\n",
      "\n",
      "Model =  Neural\n",
      "Validation Accuracy: 0.9443396226415094\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.95      0.94      0.94       513\n",
      "        real       0.94      0.95      0.95       547\n",
      "\n",
      "    accuracy                           0.94      1060\n",
      "   macro avg       0.94      0.94      0.94      1060\n",
      "weighted avg       0.94      0.94      0.94      1060\n",
      "\n",
      "Confusion Matrix:\n",
      "[[477  36]\n",
      " [ 31 516]]\n",
      "Test Accuracy: 0.9367924528301886\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.94      0.93      0.93       513\n",
      "        real       0.93      0.94      0.94       547\n",
      "\n",
      "    accuracy                           0.94      1060\n",
      "   macro avg       0.94      0.94      0.94      1060\n",
      "weighted avg       0.94      0.94      0.94      1060\n",
      "\n",
      "Model =  FastText\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  16113\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 2206834 lr:  0.000000 avg.loss:  0.017120 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9471698113207547\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.94      0.96      0.95       513\n",
      "        real       0.96      0.94      0.95       547\n",
      "\n",
      "    accuracy                           0.95      1060\n",
      "   macro avg       0.95      0.95      0.95      1060\n",
      "weighted avg       0.95      0.95      0.95      1060\n",
      "\n",
      "Validation Accuracy: 0.9471698113207547\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.94      0.96      0.95       513\n",
      "        real       0.96      0.94      0.95       547\n",
      "\n",
      "    accuracy                           0.95      1060\n",
      "   macro avg       0.95      0.95      0.95      1060\n",
      "weighted avg       0.95      0.95      0.95      1060\n",
      "\n",
      "Confusion Matrix:\n",
      "[[484  29]\n",
      " [ 34 513]]\n",
      "Test Accuracy: 0.940566037735849\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.93      0.94      0.94       513\n",
      "        real       0.95      0.94      0.94       547\n",
      "\n",
      "    accuracy                           0.94      1060\n",
      "   macro avg       0.94      0.94      0.94      1060\n",
      "weighted avg       0.94      0.94      0.94      1060\n",
      "\n",
      "Model =  kMeans\n",
      "Figure(640x480)\n",
      "Confusion Matrix:\n",
      "[[427  86]\n",
      " [104 443]]\n",
      "Test Accuracy: 0.8207547169811321\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.80      0.83      0.82       513\n",
      "        real       0.84      0.81      0.82       547\n",
      "\n",
      "    accuracy                           0.82      1060\n",
      "   macro avg       0.82      0.82      0.82      1060\n",
      "weighted avg       0.82      0.82      0.82      1060\n",
      "\n",
      "Model =  SVM\n",
      "Accuracy: 0.9452830188679245\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.94      0.95      0.94       513\n",
      "        real       0.95      0.94      0.95       547\n",
      "\n",
      "    accuracy                           0.95      1060\n",
      "   macro avg       0.95      0.95      0.95      1060\n",
      "weighted avg       0.95      0.95      0.95      1060\n",
      "\n",
      "Confusion Matrix:\n",
      "[[482  31]\n",
      " [ 36 511]]\n",
      "Test Accuracy: 0.9367924528301886\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.93      0.94      0.94       513\n",
      "        real       0.94      0.93      0.94       547\n",
      "\n",
      "    accuracy                           0.94      1060\n",
      "   macro avg       0.94      0.94      0.94      1060\n",
      "weighted avg       0.94      0.94      0.94      1060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import fasttext\n",
    "import subprocess\n",
    "\n",
    "\n",
    "models_names = [\n",
    "    \"KNN\",\n",
    "    \"Logistic\",\n",
    "    \"Neural\",\n",
    "    \"FastText\",\n",
    "    \"kMeans\",\n",
    "    \"SVM\"\n",
    "]\n",
    "# Print the list of models\n",
    "# print(models[int(sys.argv[1])])\n",
    "for model in models_names:\n",
    "    print(\"Model = \",model)\n",
    "    subprocess.run(['python3', model+'.py'])\n",
    "    if model==\"FastText\":\n",
    "        models = fasttext.load_model('FastText.bin')\n",
    "    # Load your precomputed TF-IDF features\n",
    "    else:\n",
    "        dbfile = open(model, 'rb')\n",
    "        models = pickle.load(dbfile)\n",
    "    dbfile = open('Test', 'rb')\n",
    "    test_data = pickle.load(dbfile)\n",
    "    dbfile = open('Test', 'rb')\n",
    "    y_test = pd.read_csv(\"test_data.csv\")\n",
    "    # Make predictions on the test set\n",
    "    if model==\"FastText\":\n",
    "        y_pred = models.predict(y_test['X'].tolist())\n",
    "        y_val_pred_labels = [label[0].replace('__label__', '') for label in y_pred[0]]\n",
    "        conf_matrix = confusion_matrix(y_test['y'].tolist(), y_val_pred_labels)\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(conf_matrix)\n",
    "        # Print accuracy and classification report for validation set\n",
    "        accuracy_val = accuracy_score(y_test['y'].tolist(), y_val_pred_labels)\n",
    "        print(\"Test Accuracy:\", accuracy_val)\n",
    "        print(\"Test Classification Report:\\n\", classification_report(y_test['y'].tolist(), y_val_pred_labels))\n",
    "    elif model==\"kMeans\":\n",
    "        train_clusters = models.predict(test_data)\n",
    "    \n",
    "        # Create a new DataFrame with cluster assignments\n",
    "        cluster_df_train = pd.DataFrame({'cluster': train_clusters, 'y': y_test['y']})\n",
    "        # Map cluster labels to the most frequent true label in each cluster\n",
    "        cluster_label_mapping = cluster_df_train.groupby('cluster')['y'].agg(lambda x: x.value_counts().index[0]).to_dict()\n",
    "        cluster_df_train['predicted_label'] = cluster_df_train['cluster'].map(cluster_label_mapping)\n",
    "        conf_matrix = confusion_matrix(cluster_df_train['y'], cluster_df_train['predicted_label'])\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(conf_matrix)\n",
    "        # Print accuracy and classification report for validation set\n",
    "        accuracy_val = accuracy_score(cluster_df_train['y'], cluster_df_train['predicted_label'])\n",
    "        print(\"Test Accuracy:\", accuracy_val)\n",
    "        print(\"Test Classification Report:\\n\", classification_report(cluster_df_train['y'], cluster_df_train['predicted_label']))\n",
    "    else:\n",
    "        y_pred = models.predict(test_data)\n",
    "        conf_matrix = confusion_matrix(y_test['y'], y_pred)\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(conf_matrix)\n",
    "        # Print accuracy and classification report for validation set\n",
    "        accuracy_val = accuracy_score(y_test['y'], y_pred)\n",
    "        print(\"Test Accuracy:\", accuracy_val)\n",
    "        print(\"Test Classification Report:\\n\", classification_report(y_test['y'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82436d3-4503-4678-86a9-eb364c7cc168",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
